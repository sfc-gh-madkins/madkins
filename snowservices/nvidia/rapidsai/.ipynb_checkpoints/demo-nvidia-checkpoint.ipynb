{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cec47125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import sproc, servicesproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a755f459",
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_parameters = {\n",
    "    \"account\": \"VUA92284\",\n",
    "    \"user\": \"snowflake_nvidia\",\n",
    "    \"password\": os.environ['SNOWFLAKE_TEMP_PASSWORD'],\n",
    "    \"role\": \"SNOWFLAKE_NVIDIA\",  # optional\n",
    "    \"warehouse\": \"SNOWFLAKE_NVIDIA\",  # medium snowpark-optimized\n",
    "    \"database\": \"SNOWFLAKE_NVIDIA\",  \n",
    "    \"schema\": \"PUBLIC\",  \n",
    "  }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169db876",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2c64f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df56fbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "152f9ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.003143442GB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0:00:01.610848s'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "snowdf = session.table('\"SNOWFLAKE_NVIDIA\".\"PUBLIC\".\"TPCDS_SF10TCL_TRAINING\"').limit(rows) #62,726,989 / 1.4 GB compressed\n",
    "snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "\n",
    "train_x = snowdf.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
    "train_y = snowdf.select(\"TOTAL_SALES\").to_pandas()\n",
    "\n",
    "print(str(train_x.memory_usage(deep=True, index=True).sum()/1_000_000_000) + 'GB') #GB\n",
    "\n",
    "cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
    "num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "transformers=[('num', num_pipeline, num_cols),\n",
    "              ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ])\n",
    "\n",
    "pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                    ('xgboost', XGBRegressor())])\n",
    "pipe.fit(train_x, train_y)\n",
    "\n",
    "end = datetime.now()\n",
    "\n",
    "joblib.dump(pipe, '../triton/triton-model-repo/model.joblib')\n",
    "#session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
    "str(end-start)+'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4004ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb362e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_config(model_dir, deployment_type='gpu', storage_type='AUTO'):\n",
    "    if deployment_type.lower() == 'cpu':\n",
    "        instance_kind = 'KIND_CPU'\n",
    "    else:\n",
    "        instance_kind = 'KIND_GPU'\n",
    "\n",
    "    config_text = f\"\"\"backend: \"fil\"\n",
    "max_batch_size: {max_batch_size}\n",
    "input [                                 \n",
    " {{  \n",
    "    name: \"input__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ {features} ]                    \n",
    "  }} \n",
    "]\n",
    "output [\n",
    " {{\n",
    "    name: \"output__0\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ {num_classes} ]\n",
    "  }}\n",
    "]\n",
    "instance_group [{{ kind: {instance_kind} }}]\n",
    "parameters [\n",
    "  {{\n",
    "    key: \"model_type\"\n",
    "    value: {{ string_value: \"xgboost_json\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"predict_proba\"\n",
    "    value: {{ string_value: \"hrÎ©true\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"output_class\"\n",
    "    value: {{ string_value: \"true\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"threshold\"\n",
    "    value: {{ string_value: \"0.5\" }}\n",
    "  }},\n",
    "  {{\n",
    "    key: \"storage_type\"\n",
    "    value: {{ string_value: \"{storage_type}\" }}\n",
    "  }}\n",
    "]\n",
    "\n",
    "dynamic_batching {{\n",
    "  max_queue_delay_microseconds: 100\n",
    "}}\"\"\"\n",
    "    config_path = os.path.join(model_dir, 'config.pbtxt')\n",
    "    with open(config_path, 'w') as file_:\n",
    "        file_.write(config_text)\n",
    "\n",
    "    return config_pathgwy4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c01af90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164157af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1f042d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f00eb1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dockerfile    demo.ipynb    model.joblib\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m   manifest.yaml server.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a878c86f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of package scikit-learn in the local environment is 1.2.1, which does not fit the criteria for the requirement scikit-learn. Your UDF might not work when the package version is different between the server and your local environment\n",
      "The version of package xgboost in the local environment is 1.7.3, which does not fit the criteria for the requirement xgboost. Your UDF might not work when the package version is different between the server and your local environment\n"
     ]
    }
   ],
   "source": [
    "@sproc(packages=['snowflake-snowpark-python','scikit-learn', 'xgboost'])\n",
    "def train_model(session: Session) -> str:\n",
    "    \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from xgboost import XGBRegressor\n",
    "    import joblib\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    start = datetime.now()\n",
    "    \n",
    "    snowdf = session.table('\"SNOWFLAKE_NVIDIA\".\"PUBLIC\".\"TPCDS_SF10TCL_TRAINING\"').limit(rows) #62,726,989 / 1.4 GB compressed\n",
    "    snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "\n",
    "    train_x = snowdf.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
    "    train_y = snowdf.select(\"TOTAL_SALES\").to_pandas()\n",
    "\n",
    "    cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
    "    num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', num_pipeline, num_cols),\n",
    "                  ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ])\n",
    "\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                        ('xgboost', XGBRegressor())])\n",
    "    pipe.fit(train_x, train_y)\n",
    "\n",
    "    end = datetime.now()\n",
    "\n",
    "    #test_preds = pipe.predict(test_x)\n",
    "    #rmse = mean_squared_error(test_y, test_preds)\n",
    "    #model_file = os.path.join('/tmp', 'model.joblib')\n",
    "    #joblib.dump(pipe, model_file)\n",
    "    #session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
    "    return str(end-start)+'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0544124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.4 ms, sys: 9.53 ms, total: 37 ms\n",
      "Wall time: 4min 51s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'0:04:49.208784s'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e906c923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "281d9a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@servicesproc(snowservice='NVIDIA', packages=['snowflake-snowpark-python','scikit-learn', 'xgboost'])\n",
    "def train_model(session: Session) -> str:\n",
    "    \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from xgboost import XGBRegressor\n",
    "    import joblib\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "    \n",
    "    start = datetime.now()\n",
    "    \n",
    "    snowdf = session.table('\"SNOWFLAKE_NVIDIA\".\"PUBLIC\".\"TPCDS_SF10TCL_TRAINING\"').limit(rows) #62,726,989 / 1.4 GB compressed\n",
    "    snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "\n",
    "    train_x = snowdf.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
    "    train_y = snowdf.select(\"TOTAL_SALES\").to_pandas()\n",
    "\n",
    "    cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
    "    num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', num_pipeline, num_cols),\n",
    "                  ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ], verbose=True)\n",
    "\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                        ('xgboost', XGBRegressor())], verbose=True)\n",
    "                        #('xgboost', XGBRegressor(tree_method='gpu_hist', gpu_id=0))])\n",
    "    pipe.fit(train_x, train_y)\n",
    "    \n",
    "    end = datetime.now()\n",
    "\n",
    "    #test_preds = pipe.predict(test_x)\n",
    "    #rmse = mean_squared_error(test_y, test_preds)\n",
    "    #model_file = os.path.join('/tmp', 'model.joblib')\n",
    "    #joblib.dump(pipe, model_file)\n",
    "    #session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
    "    return str(end-start)+'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4c1bcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.92 ms, sys: 2.77 ms, total: 8.69 ms\n",
      "Wall time: 1min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': '0:01:29.022231s'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5cd113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5a2015a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@servicesproc(snowservice='NVIDIA', packages=['snowflake-snowpark-python','scikit-learn', 'xgboost'])\n",
    "def train_model(session: Session) -> str:\n",
    "    \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    # from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from cuml.preprocessing import StandardScaler, SimpleImputer, MinMaxScaler #OneHotEncoder,\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "    from xgboost import XGBRegressor\n",
    "    import joblib\n",
    "    import os\n",
    "    from datetime import datetime\n",
    "\n",
    "    start = datetime.now()\n",
    "\n",
    "    snowdf = session.table('\"SNOWFLAKE_NVIDIA\".\"PUBLIC\".\"TPCDS_SF10TCL_TRAINING\"').limit(rows) #62,726,989 / 1.4 GB compressed\n",
    "    snowdf = snowdf.drop(['CUSTOMER_SK', 'C_CURRENT_HDEMO_SK', 'C_CURRENT_ADDR_SK', 'C_CUSTOMER_ID', 'CA_ADDRESS_SK', 'CD_DEMO_SK'])\n",
    "\n",
    "    train_x = snowdf.drop(\"TOTAL_SALES\").to_pandas() # drop labels for training set\n",
    "    train_y = snowdf.select(\"TOTAL_SALES\").to_pandas()\n",
    "\n",
    "    cat_cols = ['CA_ZIP', 'CD_GENDER', 'CD_MARITAL_STATUS', 'CD_CREDIT_RATING', 'CD_EDUCATION_STATUS']\n",
    "    num_cols = ['C_BIRTH_YEAR', 'CD_DEP_COUNT']\n",
    "\n",
    "    num_pipeline = Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('std_scaler', StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', num_pipeline, num_cols),\n",
    "                  ('encoder', OneHotEncoder(handle_unknown=\"ignore\"), cat_cols) ], verbose=True)\n",
    "\n",
    "    pipe = Pipeline([('preprocessor', preprocessor), \n",
    "                        #('xgboost', XGBRegressor())])\n",
    "                        ('xgboost', XGBRegressor(tree_method='gpu_hist'))], verbose=True)\n",
    "    pipe.fit(train_x, train_y)\n",
    "\n",
    "    end = datetime.now()\n",
    "\n",
    "    #test_preds = pipe.predict(test_x)\n",
    "    #rmse = mean_squared_error(test_y, test_preds)\n",
    "    #model_file = os.path.join('/tmp', 'model.joblib')\n",
    "    #joblib.dump(pipe, model_file)\n",
    "    #session.file.put(model_file, \"@ml_models\",overwrite=True)\n",
    "    return str(end-start)+'s'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f153c096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.66 ms, sys: 2.89 ms, total: 9.55 ms\n",
      "Wall time: 33.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'result': '0:00:32.629955s'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c5e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acfcaba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {'data': [[0, 1001, 's'], [1, 1002, 's'], [2, 1003, 's'], [3, 1004, 's'], [4, 1005, 's']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34db8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b85d2599",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(payload['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db4d29b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1001], [1, 1002], [2, 1003], [3, 1004], [4, 1005]]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[0,1]].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6033326a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': [[0, 1001], [1, 1002], [2, 1003], [3, 1004], [4, 1005]]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'data': df[[0,1]].values.tolist()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209ef1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#no cold start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3a87a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ram = snowdf.memory_usage(deep=True, index=True).sum()/1_000_000_000 #GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70781b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
